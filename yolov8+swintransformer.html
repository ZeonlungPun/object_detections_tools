
    <html lang="zh-CN">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
      <body class="nodata " style="">    
     
        <main style="width:100%">  
        <div class="blog-content-box"> 
            <div class="article-title-box">
                <h1 class="title-article" id="articleContentId">YOLOv8改进 | 主干篇 | SwinTransformer替换Backbone（附代码 + 详细修改步骤 +原理介绍）</h1>
            </div><div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-044f2cf1dc.css">
                <div id="content_views" class="htmledit_views">
                    <h2 id="%E4%B8%80%E3%80%81%E6%9C%AC%E6%96%87%E4%BB%8B%E7%BB%8D"><a name="t0"></a>一、本文介绍</h2> 
<p>本文给大家带来的改进机制是利用<span style="color:#1a439c;"><strong>Swin Transformer</strong></span>替换<span style="color:#ed7976;"><strong>YOLOv8中的骨干网络</strong></span>其是一个开创性的视觉<a href="https://so.csdn.net/so/search?q=%E5%8F%98%E6%8D%A2%E5%99%A8&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E5%8F%98%E6%8D%A2%E5%99%A8&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;变换器\&quot;}&quot;}" data-tit="变换器" data-pretit="变换器">变换器</a>模型，它通过使用位移窗口来构建分层的特征图，有效地适应了计算机视觉任务。与传统的变换器模型不同，Swin Transformer的自注意力计算仅限于局部窗口内，使得<span style="color:#38d8f0;"><strong>计算复杂度与图像大小成线性关系，而非二次方</strong></span>。这种设计不仅提高了模型的效率，还保持了强大的特征提取能力。Swin Transformer的创新在于其能够在不同层次上捕捉图像的细节和全局信息，使其成为各种视觉任务的强大通用骨干网络。<strong><span style="color:#ff9900;">亲测在小目标检测和大尺度目标检测的数据集上都有涨点效果。</span></strong></p> 
<p><img alt="" height="681" src="https://img-blog.csdnimg.cn/direct/0507a234975d45b889940a1b82769db8.png" width="1124"></p> 
<p><strong><span style="color:#fe2c24;">推荐指数：</span>⭐⭐⭐⭐</strong></p> 
<p><strong><span style="color:#fe2c24;">涨点效果：</span>⭐⭐⭐⭐</strong></p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24;">专栏目录：</span><strong><a href="https://snu77.blog.csdn.net/article/details/135309007" rel="nofollow" title="YOLOv8改进有效系列目录 | 包含卷积、主干、检测头、注意力机制、Neck上百种创新机制">YOLOv8改进有效系列目录 | 包含卷积、主干、检测头、注意力机制、Neck上百种创新机制</a></strong></strong></p> 
</blockquote> 
<blockquote> 
 <p><strong><span style="color:#fe2c24;">专栏回顾：</span><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><a href="https://blog.csdn.net/java1314777/category_12483754.html" title="YOLOv8改进系列专栏——本专栏持续复习各种顶会内容——科研必备">YOLOv8改进系列专栏——本专栏持续复习各种顶会内容——科研必备</a></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>&nbsp;&nbsp;&nbsp;&nbsp;</strong></p> 
</blockquote> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><strong><a href="#t1" rel="nofollow" target="_self">一、本文介绍</a></strong></p> 
<p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><strong><a href="#t2" rel="nofollow" target="_self">二、Swin Transformer原理</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t3" rel="nofollow" target="_self">2.1&nbsp;Swin Transformer的基本原理</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t4" rel="nofollow" target="_self">2.2&nbsp;层次化特征映射</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t5" rel="nofollow" target="_self">2.3&nbsp;局部自注意力计算</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t6" rel="nofollow" target="_self">2.4&nbsp;移动窗口自注意力</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t7" rel="nofollow" target="_self">2.5&nbsp;移动窗口分区</a></strong></p> 
<p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><strong>&nbsp;<a href="#t8" rel="nofollow" target="_self">三、&nbsp;Swin Transformer的完整代码</a></strong></p> 
<p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><strong><a href="#t9" rel="nofollow" target="_self">&nbsp;四、手把手教你添加Swin Transformer网络结构</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t10" rel="nofollow" target="_self">修改一</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t11" rel="nofollow" target="_self">修改二</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t12" rel="nofollow" target="_self">修改三&nbsp;</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t13" rel="nofollow" target="_self">修改四</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t14" rel="nofollow" target="_self">修改五&nbsp;</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t15" rel="nofollow" target="_self">修改六&nbsp;</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t16" rel="nofollow" target="_self">修改七</a></strong></p> 
<p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><strong><a href="#t17" rel="nofollow" target="_self">修改八</a></strong></p> 
<p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><strong><a href="#t18" rel="nofollow" target="_self">五、Swin Transformer的yaml文件</a></strong></p> 
<p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><strong><a href="#t19" rel="nofollow" target="_self">六、成功运行记录&nbsp;</a></strong></p> 
<p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><strong><a href="#t20" rel="nofollow" target="_self">七、本文总结</a></strong></p> 
<hr id="hr-toc"> 
<h2><a name="t1"></a></h2> 
<h2><a name="t2"></a><strong>二、Swin Transformer原理</strong></h2> 
<p><img alt="" height="298" src="https://img-blog.csdnimg.cn/direct/83f39973780140db9ba4527b07ea80e2.png" width="1200"></p> 
<p><span style="color:#fe2c24;"><strong>论文地址：<a class="link-info" href="https://arxiv.org/pdf/2103.14030.pdf" rel="nofollow" title="官方论文地址">官方论文地址</a></strong></span></p> 
<p><span style="color:#fe2c24;"><strong>代码地址：<a class="link-info" href="https://github.com/microsoft/Swin-Transformer" title="官方代码地址">官方代码地址</a></strong></span></p> 
<p><img alt="" height="405" src="https://img-blog.csdnimg.cn/direct/8d52404a073e454889cab624179aa842.png" width="1200"></p> 
<p></p> 
<hr> 
<h3 id="2.1%C2%A0Swin%20Transformer%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><a name="t3"></a>2.1&nbsp;<strong>Swin Transformer的基本原理</strong></h3> 
<p><span style="color:#fe2c24;"><strong>Swin Transformer</strong></span>是一个新的视觉变换器，能够作为通用的计算机视觉骨干网络。这个模型解决了将Transformer从语言处理领域适应到视觉任务中的挑战，主要是因为这两个领域之间存在差异，例如视觉实体的尺度变化大，以及图像中像素的高分辨率与文本中的单词相比。下图对比展示了Swin Transformer与Vision Transformer (ViT)的不同之处，清楚地展示了Swin Transformer在<span style="color:#4da8ee;"><strong>构建特征映射和处理计算复杂度方面</strong></span>的创新优势。</p> 
<p class="img-center"><img alt="" height="314" src="https://img-blog.csdnimg.cn/direct/3c2f4571e5c54b4eb1305151dfa0a00c.png" width="600"></p> 
<p><strong>(a) Swin Transformer：</strong>提出的Swin Transformer通过在更深层次合并图像小块（灰色部分所示）来构建层次化的特征映射。在每个局部窗口（红色部分所示）内只计算自注意力，因此它对输入图像大小有线性的计算复杂度。它可以作为通用的骨干网络，用于图像分类和密集识别任务，如分割和检测。</p> 
<p><strong>(b) Vision Transformer (ViT)：</strong>以前的视觉Transformer模型（如ViT）产生单一低分辨率的特征映射，并且由于全局自注意力的计算，其计算复杂度与输入图像大小呈二次方关系。</p> 
<p><span style="color:#ff9900;"><strong>我们可以将Swin Transformer的基本原理分为以下几点：</strong></span></p> 
<p><strong>1. 层次化特征映射：</strong>Swin Transformer通过合并图像的相邻小块（patches），在更深的Transformer层次中逐步构建层次化的特征映射。这样的层次化特征映射可以方便地利用密集预测的高级技术，如特征金字塔网络（Feature Pyramid Networks, FPN）或U-Net。</p> 
<p><strong>2. 局部自注意力计算：</strong>为了实现线性计算复杂性，Swin Transformer在非重叠的局部窗口内计算自注意力，这些窗口是通过划分图像来创建的。每个窗口内的小块数量是固定的，因此计算复杂性与图像大小成线性关系。</p> 
<p><strong>3. 移动窗口自注意力（Shifted Window based Self-Attention）：</strong>标准的Transformer架构在全局范围内计算自注意力，即计算一个标记与所有其他标记之间的关系。这种全局计算导致与标记数量成二次方的计算复杂性，不适用于许多需要处理大规模高维数据的视觉问题。Swin Transformer通过一个基于移动窗口的多头自注意力（MSA）模块取代了传统的MSA模块。每个Swin Transformer块由一个基于移动窗口的MSA模块组成，然后是两层带有GELU非线性的MLP，之前是LayerNorm（LN）层，之后是残差连接。</p> 
<p><strong>4. 移动窗口分区：</strong>为了在连续的Swin Transformer块中引入跨窗口连接的同时保持非重叠窗口的有效计算，提出了一种移动窗口分区方法。这种方法在连续的块之间交替使用两种分区配置。第一个模块使用常规的窗口分区策略，然后下一个模块采用的窗口配置与前一层相比，通过移动窗口偏移了一定距离，从而实现窗口的交替。</p> 
<p>下图详细展示了<span style="color:#4da8ee;"><strong>Swin Transformer的架构和两个连续Swin Transformer块的设计</strong></span>。图中的W-MSA和SW-MSA分别代表带有常规和移动窗口配置的多头自注意力模块。这两种类型的注意力模块交替使用，允许模型在保持局部计算的同时，也能够捕捉更广泛的上下文信息。</p> 
<p class="img-center"><img alt="" height="357" src="https://img-blog.csdnimg.cn/direct/cb6666f192a34e67a8acae70c096af1f.png" width="1187"></p> 
<p><strong>(a) 架构（Architecture）：</strong>图展示了Swin Transformer的四个阶段。每个阶段都包含若干Swin Transformer块。输入图像首先通过“Patch Partition”被划分成小块，并通过“Linear Embedding”转换成向量序列。各个阶段通过“Patch Merging”操作降低<a href="https://so.csdn.net/so/search?q=%E7%89%B9%E5%BE%81%E5%9B%BE&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E7%89%B9%E5%BE%81%E5%9B%BE&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;特征图\&quot;}&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E7%89%B9%E5%BE%81%E5%9B%BE&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;特征图\&quot;}&quot;}" data-tit="特征图" data-pretit="特征图">特征图</a>的分辨率，同时增加特征维数（例如，第一阶段输出的特征维数为C，第二阶段为2C，依此类推）。</p> 
<p><strong>(b) 两个连续的Swin Transformer块（Two Successive Swin Transformer Blocks）：</strong>每个Swin Transformer块由多头自注意力模块（W-MSA和SW-MSA）和多层感知机（MLP）组成，其中W-MSA使用常规窗口配置，而SW-MSA使用移动窗口配置。每个块内部，先是LayerNorm（LN）层，然后是自注意力模块，再是另一个LayerNorm层，最后是MLP。块之间通过残差连接进行连接，这样的设计可以避免深层网络中的梯度消失问题，并允许信息在网络中更有效地流动。</p> 
<p></p> 
<hr> 
<h3 id="2.2%C2%A0%E5%B1%82%E6%AC%A1%E5%8C%96%E7%89%B9%E5%BE%81%E6%98%A0%E5%B0%84"><a name="t4"></a>2.2&nbsp;<strong>层次化特征映射</strong></h3> 
<p>层次化特征映射可以使<span style="color:#4da8ee;"><strong>Swin Transformer有效地处理不同分辨率的特征</strong></span>，并适用于各种视觉任务，如图像分类、对象检测和语义分割。这种层次化设计使Swin Transformer与以往基于Transformer的架构（这些架构产生单一分辨率的特征图并具有二次方复杂度）形成对比，后者不适合需要在像素级进行密集预测的视觉任务。Swin Transformer的<span style="color:#ff9900;"><strong>层次化特征映射</strong></span>主要通过以下步骤实现：</p> 
<p><strong>1. 分块和线性嵌入：</strong>首先，输入图像被分割成小块（通常是4x4像素大小），每个小块被视为一个“标记”，其特征是原始像素RGB值的串联。然后，一个线性嵌入层被应用于这些原始值特征，将其投影到任意维度（表示为C）。这些步骤构成了所谓的“第1阶段”。</p> 
<p><strong>2. 分块合并：</strong>随着网络深入，通过合并层减少标记的数量，从而降低特征图的分辨率。例如，第一个合并层将每组2x2相邻小块的特征合并，并应用一个线性层到这些4C维度的串联特征上，这样做将标记的数量减少了4倍（分辨率降低了2倍），并将输出维度设为2C。这个过程在后续的“第2阶段”、“第3阶段”和“第4阶段”中重复，分别产生更低分辨率的输出。</p> 
<p><strong>3. 层次化特征图：</strong>通过在更深的Transformer层合并相邻小块，Swin Transformer构建了层次化的特征映射。这些层次化特征映射允许模型方便地使用密集预测的高级技术，例如特征金字塔网络（FPN）或U-Net。</p> 
<p><strong>4. 计算效率：</strong>Swin Transformer在非重叠的局部窗口内局部计算自注意力，从而实现了线性的计算复杂度。每个窗口中的小块数量是固定的，因此复杂度与图像大小成线性关系。</p> 
<p></p> 
<hr> 
<h3 id="2.3%C2%A0%E5%B1%80%E9%83%A8%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%AE%A1%E7%AE%97"><a name="t5"></a>2.3&nbsp;<strong>局部自注意力计算</strong></h3> 
<p><span style="color:#ff9900;"><strong>Swin Transformer的局部自注意力计算通过</strong></span>在小窗口内计算自注意力以及通过移动窗口在连续层之间引入跨窗口的信息流通，使得计算更加高效，同时保留了模型捕捉长距离依赖的能力。Swin Transformer中的局部自注意力计算我们可以通过以下方式实现：</p> 
<p><strong>1. 替代标准多头自注意力模块：</strong>Swin Transformer使用基于移动窗口的多头自注意力（MSA）模块替代了传统Transformer块中的标准多头自注意力模块，其他层保持不变。每个Swin Transformer块由一个基于移动窗口的MSA模块组成，后跟一个两层的MLP，中间包含GELU非线性激活函数。在每个MSA模块和MLP之前都会应用一个LayerNorm（LN）层，每个模块之后都会应用残差连接。</p> 
<p><strong>2. 在各个窗口内计算自注意力：</strong>在每一层中，采用常规的窗口分区方案，每个窗口内部独立计算自注意力。在下一层中，窗口分区会发生移动，形成新的窗口。新窗口中的自注意力计算会跨越之前层中窗口的边界，建立它们之间的连接。</p> 
<p><strong>3. 非重叠窗口中的自注意力：</strong>为了有效的建模，Swin Transformer在非重叠的局部窗口内计算自注意力。这些窗口被安排以均匀非重叠的方式分割图像。假设每个窗口包含M×M个小块，全局MSA模块和基于窗口的MSA模块的计算复杂度分别为二次方和线性，当M固定时（默认设为7）。</p> 
<p><strong>4. 循环位移和掩码机制：</strong>提出了一种通过循环位移来提高批量计算的效率的方法。通过这种位移，一个批次的窗口可能由几个在特征图中不相邻的子窗口组成，因此采用掩码机制限制在每个子窗口内计算自注意力。这种循环位移保持了批次窗口的数量与常规窗口分区相同。</p> 
<p><strong>5. 窗口间的位移：</strong>为了在连续层之间实现更高效的硬件实现，Swin Transformer提出在连续层之间位移窗口，这样的位移允许跨窗口的连接，同时维持计算的高效性。</p> 
<p><strong>6. 相对位置偏置：</strong>在计算自注意力时，Swin Transformer包括了相对位置偏置B，以增强模型对不同位置之间关系的学习能力。</p> 
<p></p> 
<hr> 
<h3 id="2.4%C2%A0%E7%A7%BB%E5%8A%A8%E7%AA%97%E5%8F%A3%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B"><a name="t6"></a>2.4&nbsp;<strong>移动窗口自注意力</strong></h3> 
<p>移动窗口自注意力是Swin Transformer设计的核心元素，它<span style="color:#ff9900;"><strong>通过在局部窗口内计算自注意力</strong></span>并在连续层之间引入窗口位移，以实现高效的计算和强大的建模能力。在Swin Transformer论文中，移动窗口自注意力（shifted window self-attention）的<span style="color:#4da8ee;"><strong>主要特点</strong></span>包括：</p> 
<p><strong>1. 替代多头自注意力模块：</strong>在Swin Transformer块中，标准的<span style="color:#4da8ee;"><strong>多头自注意力（MSA）模块</strong></span>被基于移动窗口的MSA模块替换。这种基于移动窗口的MSA模块后跟一个两层的MLP，中间有GELU非线性激活函数。每个MSA模块和MLP之前都会应用一个LayerNorm（LN）层，每个模块之后都会应用残差连接。</p> 
<p><strong>2. 移动窗口分区：</strong>在连续的Swin Transformer块中，窗口分区策略在每一层之间交替。在某一层中，采用常规窗口分区，而在下一层中，窗口分区会发生移动，从而形成新的窗口。这种移动窗口分区方法能够跨越前一层中窗口的边界，提供窗口间的连接。</p> 
<p><strong>3. 交替分区配置：</strong>移动窗口分区方法在连续的Swin Transformer块中交替使用两种分区配置。例如，第一个模块从左上角像素开始使用常规窗口分区策略，接着下一个模块采用的窗口配置将与前一层相比移动一定距离。</p> 
<p><strong>4. 移动窗口自注意力的计算：</strong>移动窗口自注意力计算的有效性不仅在图像分类、目标检测和语义分割任务中得到了验证，而且它的实现也被证明在所有MLP架构中有益。</p> 
<p><strong>5. 效率：</strong>相比于滑动窗口方法，移动窗口方法具有更低的延迟，但在建模能力上却相似。此外，移动窗口方法也有助于提高批量计算的效率。</p> 
<p><strong>6. 连续块的计算：</strong>在移动窗口分区方法中，连续的Swin Transformer块的<span style="color:#4da8ee;"><strong>计算方式</strong></span>如下：<img alt="\hat{z_l} = W\text{-}MSA(LN(z_{l-1})) + z_{l-1}" class="mathcode" src="https://latex.csdn.net/eq?%5Chat%7Bz_l%7D%20%3D%20W%5Ctext%7B-%7DMSA%28LN%28z_%7Bl-1%7D%29%29%20&amp;plus;%20z_%7Bl-1%7D">，然后是MLP层，之后是<img alt="\\hat{z_{l+1}} = SW\text{-}MSA(LN(z_l)) + z_l" class="mathcode" src="https://latex.csdn.net/eq?%5C%5Chat%7Bz_%7Bl&amp;plus;1%7D%7D%20%3D%20SW%5Ctext%7B-%7DMSA%28LN%28z_l%29%29%20&amp;plus;%20z_l">。这里，<img alt="\hat{z_l}" class="mathcode" src="https://latex.csdn.net/eq?%5Chat%7Bz_l%7D">和 <img alt="z_l" class="mathcode" src="https://latex.csdn.net/eq?z_l">分别代表块l的(S)W-MSA模块和MLP模块的输出特征。</p> 
<p>下面我给大家展示了所提出的Swin Transformer架构中用于<span style="color:#ff9900;"><strong>计算自注意力的移动窗口方法</strong></span>。</p> 
<p class="img-center"><img alt="" height="229" src="https://img-blog.csdnimg.cn/direct/f8429acf1ab14e3ebc7982f71f17d283.png" width="591"></p> 
<p>在第l层（左侧），采用了常规窗口划分方案，并且在每个窗口内计算自注意力。在接下来的第l+1层（右侧），窗口划分被移动，结果在新的窗口中进行了自注意力计算。这些新窗口中的自注意力计算跨越了l层中之前窗口的边界，提供了它们之间的连接。这种移动窗口方法提高了效率，<span style="color:#4da8ee;"><strong>因为它限制了自注意力计算在非重叠的局部窗口内，同时允许窗口间的交叉连接。&nbsp;</strong></span></p> 
<p></p> 
<hr> 
<h3 id="2.5%C2%A0%E7%A7%BB%E5%8A%A8%E7%AA%97%E5%8F%A3%E5%88%86%E5%8C%BA"><a name="t7"></a><span style="color:#0d0016;">2.5&nbsp;</span><strong>移动窗口分区</strong></h3> 
<p>移动窗口分区是Swin Transformer中一项关键的创新，它<span style="color:#ff9900;"><strong>通过在连续层之间交替窗口的分区方式</strong></span>，有效地促进了信息在窗口之间的流动，同时保持了处理高分辨率图像时的计算效率。下面我将通过图片<span style="color:#4da8ee;"><strong>解释如何使用循环位移来计算在移动窗口中的自注意力，以及如何高效地实施这一计算</strong></span>。</p> 
<p><img alt="" height="298" src="https://img-blog.csdnimg.cn/direct/c991b4ae1ee74caea32c0223d3d6ffb4.png" width="961"></p> 
<p></p> 
<p><strong>（1）窗口分区（Window partition）：</strong>首先，图像被分成多个窗口。<br><strong>（2）循环位移（Cyclic shift）：</strong>接着，为了计算自注意力，窗口内的像素或特征会进行循环位移。这样可以将本来不相邻的像素或特征暂时性地排列到同一个窗口内，使得可以在局部窗口中计算原本跨窗口的自注意力。<br><strong>（3）掩码多头自注意力（Masked MSA）：</strong>在经过循环位移后，可以在这些临时形成的窗口上执行掩码多头自注意力操作，以此计算注意力得分和更新特征。<br><strong>（4）逆循环位移（Reverse cyclic shift）：</strong>完成自注意力计算后，特征会进行逆循环位移，恢复到它们原来在图像中的位置。</p> 
<p></p> 
<h2 id="%E4%B8%89%E3%80%81%C2%A0Swin%20Transformer%E7%9A%84%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><a name="t8"></a>三、&nbsp;Swin Transformer的完整代码</h2> 
<pre data-index="0" class="set-code-show" name="code"><code class="hljs language-cobol"><ol class="hljs-ln hundred" style="width:1027px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">import torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">import torch.nn <span class="hljs-keyword">as</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">import torch.nn.functional <span class="hljs-keyword">as</span> F</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">import torch.utils.checkpoint <span class="hljs-keyword">as</span> checkpoint</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">import numpy <span class="hljs-keyword">as</span> np</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> timm.models.layers import DropPath, <span class="hljs-keyword">to</span>_<span class="hljs-number">2</span>tuple, trunc_normal_</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> Mlp(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string">""</span><span class="hljs-string">" Multilayer perceptron."</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def __init__(<span class="hljs-keyword">self</span>, <span class="hljs-keyword">in</span>_features, hidden_features<span class="hljs-operator">=</span>None, out_features<span class="hljs-operator">=</span>None, act_layer<span class="hljs-operator">=</span>nn.GELU, drop<span class="hljs-operator">=</span><span class="hljs-number">0</span>.):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">super</span>().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        out_features <span class="hljs-operator">=</span> out_features <span class="hljs-keyword">or</span> <span class="hljs-keyword">in</span>_features</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        hidden_features <span class="hljs-operator">=</span> hidden_features <span class="hljs-keyword">or</span> <span class="hljs-keyword">in</span>_features</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.fc<span class="hljs-number">1</span> <span class="hljs-operator">=</span> nn.Linear(<span class="hljs-keyword">in</span>_features, hidden_features)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.act <span class="hljs-operator">=</span> act_layer()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.fc<span class="hljs-number">2</span> <span class="hljs-operator">=</span> nn.Linear(hidden_features, out_features)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.drop <span class="hljs-operator">=</span> nn.Dropout(drop)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def forward(<span class="hljs-keyword">self</span>, x):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.fc<span class="hljs-number">1</span>(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.act(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.drop(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.fc<span class="hljs-number">2</span>(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.drop(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">def window_partition(x, window_<span class="hljs-keyword">size</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">"</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        x: (B, H, W, C)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        window_size (int): window size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Returns:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        windows: (num_windows*B, window_size, window_size, C)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    B, H, W, C <span class="hljs-operator">=</span> x.shape</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x <span class="hljs-operator">=</span> x.view(B, H <span class="hljs-operator">/</span><span class="hljs-operator">/</span> window_<span class="hljs-keyword">size</span>, window_<span class="hljs-keyword">size</span>, W <span class="hljs-operator">/</span><span class="hljs-operator">/</span> window_<span class="hljs-keyword">size</span>, window_<span class="hljs-keyword">size</span>, C)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    windows <span class="hljs-operator">=</span> x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>).contiguous().view(-<span class="hljs-number">1</span>, window_<span class="hljs-keyword">size</span>, window_<span class="hljs-keyword">size</span>, C)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> windows</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">def window_reverse(windows, window_<span class="hljs-keyword">size</span>, H, W):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">"</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        windows: (num_windows*B, window_size, window_size, C)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        window_size (int): Window size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        H (int): Height of image</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        W (int): Width of image</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Returns:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        x: (B, H, W, C)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    B <span class="hljs-operator">=</span> int(windows.shape[<span class="hljs-number">0</span>] <span class="hljs-operator">/</span> (H <span class="hljs-operator">*</span> W <span class="hljs-operator">/</span> window_<span class="hljs-keyword">size</span> <span class="hljs-operator">/</span> window_<span class="hljs-keyword">size</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x <span class="hljs-operator">=</span> windows.view(B, H <span class="hljs-operator">/</span><span class="hljs-operator">/</span> window_<span class="hljs-keyword">size</span>, W <span class="hljs-operator">/</span><span class="hljs-operator">/</span> window_<span class="hljs-keyword">size</span>, window_<span class="hljs-keyword">size</span>, window_<span class="hljs-keyword">size</span>, -<span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x <span class="hljs-operator">=</span> x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>).contiguous().view(B, H, W, -<span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> WindowAttention(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">" Window based multi-head self attention (W-MSA) module with relative position bias.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="63"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    It supports both of shifted and non-shifted window.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="64"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="65"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="66"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        dim (int): Number of input channels.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="67"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        window_size (tuple[int]): The height and width of the window.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="68"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        num_heads (int): Number of attention heads.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="69"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="70"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="71"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="72"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        proj_drop (float, optional): Dropout ratio of output. Default: 0.0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="73"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="74"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="75"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def __init__(<span class="hljs-keyword">self</span>, dim, window_<span class="hljs-keyword">size</span>, num_heads, qkv_bias<span class="hljs-operator">=</span><span class="hljs-keyword">True</span>, qk_scale<span class="hljs-operator">=</span>None, attn_drop<span class="hljs-operator">=</span><span class="hljs-number">0</span>., proj_drop<span class="hljs-operator">=</span><span class="hljs-number">0</span>.):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="76"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="77"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">super</span>().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="78"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.dim <span class="hljs-operator">=</span> dim</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="79"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span> <span class="hljs-operator">=</span> window_<span class="hljs-keyword">size</span>  # Wh, Ww</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="80"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.num_heads <span class="hljs-operator">=</span> num_heads</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="81"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        head_dim <span class="hljs-operator">=</span> dim <span class="hljs-operator">/</span><span class="hljs-operator">/</span> num_heads</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="82"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.scale <span class="hljs-operator">=</span> qk_scale <span class="hljs-keyword">or</span> head_dim <span class="hljs-operator">**</span> -<span class="hljs-number">0.5</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="83"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="84"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # define a parameter <span class="hljs-keyword">table</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">relative</span> position bias</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="85"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.<span class="hljs-keyword">relative</span>_position_bias_<span class="hljs-keyword">table</span> <span class="hljs-operator">=</span> nn.Parameter(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="86"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            torch.<span class="hljs-literal">zeros</span>((<span class="hljs-number">2</span> <span class="hljs-operator">*</span> window_<span class="hljs-keyword">size</span>[<span class="hljs-number">0</span>]<span class="hljs-operator"> - </span><span class="hljs-number">1</span>) <span class="hljs-operator">*</span> (<span class="hljs-number">2</span> <span class="hljs-operator">*</span> window_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>]<span class="hljs-operator"> - </span><span class="hljs-number">1</span>), num_heads))  # <span class="hljs-number">2</span><span class="hljs-operator">*</span>Wh-<span class="hljs-number">1</span> <span class="hljs-operator">*</span> <span class="hljs-number">2</span><span class="hljs-operator">*</span>Ww-<span class="hljs-number">1</span>, nH</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="87"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="88"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # <span class="hljs-keyword">get</span> pair-wise <span class="hljs-keyword">relative</span> position <span class="hljs-keyword">index</span> <span class="hljs-keyword">for</span> each token inside the window</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="89"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        coords_h <span class="hljs-operator">=</span> torch.arange(<span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>[<span class="hljs-number">0</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="90"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        coords_w <span class="hljs-operator">=</span> torch.arange(<span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="91"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        coords <span class="hljs-operator">=</span> torch.stack(torch.meshgrid([coords_h, coords_w]))  # <span class="hljs-number">2</span>, Wh, Ww</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="92"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        coords_flatten <span class="hljs-operator">=</span> torch.flatten(coords, <span class="hljs-number">1</span>)  # <span class="hljs-number">2</span>, Wh<span class="hljs-operator">*</span>Ww</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="93"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">relative</span>_coords <span class="hljs-operator">=</span> coords_flatten[:, :, None]<span class="hljs-operator"> - </span>coords_flatten[:, None, :]  # <span class="hljs-number">2</span>, Wh<span class="hljs-operator">*</span>Ww, Wh<span class="hljs-operator">*</span>Ww</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="94"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">relative</span>_coords <span class="hljs-operator">=</span> <span class="hljs-keyword">relative</span>_coords.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>).contiguous()  # Wh<span class="hljs-operator">*</span>Ww, Wh<span class="hljs-operator">*</span>Ww, <span class="hljs-number">2</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="95"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">relative</span>_coords[:, :, <span class="hljs-number">0</span>] <span class="hljs-operator">+</span><span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>[<span class="hljs-number">0</span>]<span class="hljs-operator"> - </span><span class="hljs-number">1</span>  # shift <span class="hljs-keyword">to</span> <span class="hljs-keyword">start</span> <span class="hljs-keyword">from</span> <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="96"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">relative</span>_coords[:, :, <span class="hljs-number">1</span>] <span class="hljs-operator">+</span><span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>]<span class="hljs-operator"> - </span><span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="97"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">relative</span>_coords[:, :, <span class="hljs-number">0</span>] <span class="hljs-operator">*</span><span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>]<span class="hljs-operator"> - </span><span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="98"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">relative</span>_position_<span class="hljs-keyword">index</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">relative</span>_coords.<span class="hljs-keyword">sum</span>(-<span class="hljs-number">1</span>)  # Wh<span class="hljs-operator">*</span>Ww, Wh<span class="hljs-operator">*</span>Ww</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="99"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.register_buffer(<span class="hljs-string">"relative_position_index"</span>, <span class="hljs-keyword">relative</span>_position_<span class="hljs-keyword">index</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="100"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="101"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.qkv <span class="hljs-operator">=</span> nn.Linear(dim, dim <span class="hljs-operator">*</span> <span class="hljs-number">3</span>, bias<span class="hljs-operator">=</span>qkv_bias)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="102"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.attn_drop <span class="hljs-operator">=</span> nn.Dropout(attn_drop)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="103"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.proj <span class="hljs-operator">=</span> nn.Linear(dim, dim)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="104"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.proj_drop <span class="hljs-operator">=</span> nn.Dropout(proj_drop)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="105"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="106"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        trunc_normal_(<span class="hljs-keyword">self</span>.<span class="hljs-keyword">relative</span>_position_bias_<span class="hljs-keyword">table</span>, std<span class="hljs-operator">=</span>.<span class="hljs-number">02</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="107"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.softmax <span class="hljs-operator">=</span> nn.Softmax(dim<span class="hljs-operator">=</span>-<span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="108"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="109"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def forward(<span class="hljs-keyword">self</span>, x, mask<span class="hljs-operator">=</span>None):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="110"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">" Forward function.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="111"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="112"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="113"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            x: input features with shape of (num_windows*B, N, C)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="114"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="115"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="116"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        B_, N, C <span class="hljs-operator">=</span> x.shape</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="117"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        qkv <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.qkv(x).reshape(B_, N, <span class="hljs-number">3</span>, <span class="hljs-keyword">self</span>.num_heads, C <span class="hljs-operator">/</span><span class="hljs-operator">/</span> <span class="hljs-keyword">self</span>.num_heads).permute(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="118"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        q, k, v <span class="hljs-operator">=</span> qkv[<span class="hljs-number">0</span>], qkv[<span class="hljs-number">1</span>], qkv[<span class="hljs-number">2</span>]  # make torchscript happy (cannot <span class="hljs-keyword">use</span> tensor <span class="hljs-keyword">as</span> tuple)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="119"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="120"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        q <span class="hljs-operator">=</span> q <span class="hljs-operator">*</span> <span class="hljs-keyword">self</span>.scale</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="121"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attn <span class="hljs-operator">=</span> (q @ k.transpose(-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="122"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="123"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">relative</span>_position_bias <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.<span class="hljs-keyword">relative</span>_position_bias_<span class="hljs-keyword">table</span>[<span class="hljs-keyword">self</span>.<span class="hljs-keyword">relative</span>_position_<span class="hljs-keyword">index</span>.view(-<span class="hljs-number">1</span>)].view(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="124"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>[<span class="hljs-number">0</span>] <span class="hljs-operator">*</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>], <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>[<span class="hljs-number">0</span>] <span class="hljs-operator">*</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>)  # Wh<span class="hljs-operator">*</span>Ww,Wh<span class="hljs-operator">*</span>Ww,nH</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="125"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">relative</span>_position_bias <span class="hljs-operator">=</span> <span class="hljs-keyword">relative</span>_position_bias.permute(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>).contiguous()  # nH, Wh<span class="hljs-operator">*</span>Ww, Wh<span class="hljs-operator">*</span>Ww</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="126"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attn <span class="hljs-operator">=</span> attn <span class="hljs-operator">+</span> <span class="hljs-keyword">relative</span>_position_bias.unsqueeze(<span class="hljs-number">0</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="127"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="128"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> None:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="129"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nW <span class="hljs-operator">=</span> mask.shape[<span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="130"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attn <span class="hljs-operator">=</span> attn.view(B_ <span class="hljs-operator">/</span><span class="hljs-operator">/</span> nW, nW, <span class="hljs-keyword">self</span>.num_heads, N, N) <span class="hljs-operator">+</span> mask.unsqueeze(<span class="hljs-number">1</span>).unsqueeze(<span class="hljs-number">0</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="131"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attn <span class="hljs-operator">=</span> attn.view(-<span class="hljs-number">1</span>, <span class="hljs-keyword">self</span>.num_heads, N, N)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="132"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attn <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.softmax(attn)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="133"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="134"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attn <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.softmax(attn)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="135"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="136"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attn <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.attn_drop(attn)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="137"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="138"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> (attn @ v).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).reshape(B_, N, C)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="139"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.proj(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="140"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.proj_drop(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="141"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="142"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="143"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="144"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> SwinTransformerBlock(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="145"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">" Swin Transformer Block.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="146"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="147"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="148"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        dim (int): Number of input channels.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="149"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        num_heads (int): Number of attention heads.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="150"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        window_size (int): Window size.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="151"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        shift_size (int): Shift size for SW-MSA.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="152"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="153"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="154"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="155"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        drop (float, optional): Dropout rate. Default: 0.0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="156"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        attn_drop (float, optional): Attention dropout rate. Default: 0.0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="157"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        drop_path (float, optional): Stochastic depth rate. Default: 0.0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="158"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="159"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="160"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="161"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="162"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def __init__(<span class="hljs-keyword">self</span>, dim, num_heads, window_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span><span class="hljs-number">7</span>, shift_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span><span class="hljs-number">0</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="163"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 mlp_ratio<span class="hljs-operator">=</span><span class="hljs-number">4</span>., qkv_bias<span class="hljs-operator">=</span><span class="hljs-keyword">True</span>, qk_scale<span class="hljs-operator">=</span>None, drop<span class="hljs-operator">=</span><span class="hljs-number">0</span>., attn_drop<span class="hljs-operator">=</span><span class="hljs-number">0</span>., drop_path<span class="hljs-operator">=</span><span class="hljs-number">0</span>.,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="164"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 act_layer<span class="hljs-operator">=</span>nn.GELU, norm_layer<span class="hljs-operator">=</span>nn.LayerNorm):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="165"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">super</span>().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="166"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.dim <span class="hljs-operator">=</span> dim</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="167"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.num_heads <span class="hljs-operator">=</span> num_heads</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="168"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span> <span class="hljs-operator">=</span> window_<span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="169"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span> <span class="hljs-operator">=</span> shift_<span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="170"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.mlp_ratio <span class="hljs-operator">=</span> mlp_ratio</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="171"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        assert <span class="hljs-number">0</span> <span class="hljs-operator">&lt;=</span> <span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span> <span class="hljs-operator">&lt;</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>, <span class="hljs-string">"shift_size must in 0-window_size"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="172"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="173"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.norm<span class="hljs-number">1</span> <span class="hljs-operator">=</span> norm_layer(dim)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="174"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.attn <span class="hljs-operator">=</span> WindowAttention(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="175"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            dim, window_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span><span class="hljs-keyword">to</span>_<span class="hljs-number">2</span>tuple(<span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>), num_heads<span class="hljs-operator">=</span>num_heads,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="176"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            qkv_bias<span class="hljs-operator">=</span>qkv_bias, qk_scale<span class="hljs-operator">=</span>qk_scale, attn_drop<span class="hljs-operator">=</span>attn_drop, proj_drop<span class="hljs-operator">=</span>drop)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="177"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="178"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.drop_path <span class="hljs-operator">=</span> DropPath(drop_path) <span class="hljs-keyword">if</span> drop_path <span class="hljs-operator">&gt;</span> <span class="hljs-number">0</span>. <span class="hljs-keyword">else</span> nn.Identity()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="179"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.norm<span class="hljs-number">2</span> <span class="hljs-operator">=</span> norm_layer(dim)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="180"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        mlp_hidden_dim <span class="hljs-operator">=</span> int(dim <span class="hljs-operator">*</span> mlp_ratio)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="181"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.mlp <span class="hljs-operator">=</span> Mlp(<span class="hljs-keyword">in</span>_features<span class="hljs-operator">=</span>dim, hidden_features<span class="hljs-operator">=</span>mlp_hidden_dim, act_layer<span class="hljs-operator">=</span>act_layer, drop<span class="hljs-operator">=</span>drop)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="182"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="183"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.H <span class="hljs-operator">=</span> None</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="184"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.W <span class="hljs-operator">=</span> None</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="185"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="186"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def forward(<span class="hljs-keyword">self</span>, x, mask_matrix):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="187"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">" Forward function.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="188"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="189"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="190"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            x: Input feature, tensor size (B, H*W, C).</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="191"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            H, W: Spatial resolution of the input feature.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="192"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            mask_matrix: Attention mask for cyclic shift.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="193"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="194"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        B, L, C <span class="hljs-operator">=</span> x.shape</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="195"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        H, W <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.H, <span class="hljs-keyword">self</span>.W</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="196"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        assert L <span class="hljs-operator">=</span><span class="hljs-operator">=</span> H <span class="hljs-operator">*</span> W, <span class="hljs-string">"input feature has wrong size"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="197"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="198"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        shortcut <span class="hljs-operator">=</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="199"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.norm<span class="hljs-number">1</span>(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="200"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> x.view(B, H, W, C)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="201"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="202"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # pad feature maps <span class="hljs-keyword">to</span> multiples <span class="hljs-keyword">of</span> window <span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="203"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        pad_l <span class="hljs-operator">=</span> pad_t <span class="hljs-operator">=</span> <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="204"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        pad_r <span class="hljs-operator">=</span> (<span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span><span class="hljs-operator"> - </span>W % <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>) % <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="205"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        pad_b <span class="hljs-operator">=</span> (<span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span><span class="hljs-operator"> - </span>H % <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>) % <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="206"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> F.pad(x, (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, pad_l, pad_r, pad_t, pad_b))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="207"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        _, Hp, Wp, _ <span class="hljs-operator">=</span> x.shape</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="208"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="209"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # cyclic shift</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="210"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span> <span class="hljs-operator">&gt;</span> <span class="hljs-number">0</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="211"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            shifted_x <span class="hljs-operator">=</span> torch.roll(x, shifts<span class="hljs-operator">=</span>(-<span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span>, -<span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span>), dims<span class="hljs-operator">=</span>(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="212"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attn_mask <span class="hljs-operator">=</span> mask_matrix.<span class="hljs-keyword">type</span>(x.dtype)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="213"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="214"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            shifted_x <span class="hljs-operator">=</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="215"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attn_mask <span class="hljs-operator">=</span> None</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="216"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="217"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # partition windows</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="218"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x_windows <span class="hljs-operator">=</span> window_partition(shifted_x, <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>)  # nW<span class="hljs-operator">*</span>B, window_<span class="hljs-keyword">size</span>, window_<span class="hljs-keyword">size</span>, C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="219"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x_windows <span class="hljs-operator">=</span> x_windows.view(-<span class="hljs-number">1</span>, <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>, C)  # nW<span class="hljs-operator">*</span>B, window_<span class="hljs-keyword">size</span><span class="hljs-operator">*</span>window_<span class="hljs-keyword">size</span>, C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="220"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="221"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # W-MSA<span class="hljs-operator">/</span>SW-MSA</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="222"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attn_windows <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.attn(x_windows, mask<span class="hljs-operator">=</span>attn_mask)  # nW<span class="hljs-operator">*</span>B, window_<span class="hljs-keyword">size</span><span class="hljs-operator">*</span>window_<span class="hljs-keyword">size</span>, C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="223"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="224"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # <span class="hljs-keyword">merge</span> windows</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="225"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attn_windows <span class="hljs-operator">=</span> attn_windows.view(-<span class="hljs-number">1</span>, <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>, <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>, C)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="226"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        shifted_x <span class="hljs-operator">=</span> window_reverse(attn_windows, <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>, Hp, Wp)  # B H<span class="hljs-string">' W'</span> C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="227"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="228"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # reverse cyclic shift</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="229"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span> <span class="hljs-operator">&gt;</span> <span class="hljs-number">0</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="230"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> torch.roll(shifted_x, shifts<span class="hljs-operator">=</span>(<span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span>, <span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span>), dims<span class="hljs-operator">=</span>(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="231"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="232"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> shifted_x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="233"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="234"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> pad_r <span class="hljs-operator">&gt;</span> <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> pad_b <span class="hljs-operator">&gt;</span> <span class="hljs-number">0</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="235"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> x[:, :H, :W, :].contiguous()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="236"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="237"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> x.view(B, H <span class="hljs-operator">*</span> W, C)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="238"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="239"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # FFN</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="240"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> shortcut <span class="hljs-operator">+</span> <span class="hljs-keyword">self</span>.drop_path(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="241"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> x <span class="hljs-operator">+</span> <span class="hljs-keyword">self</span>.drop_path(<span class="hljs-keyword">self</span>.mlp(<span class="hljs-keyword">self</span>.norm<span class="hljs-number">2</span>(x)))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="242"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="243"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="244"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="245"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="246"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> PatchMerging(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="247"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">" Patch Merging Layer</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="248"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="249"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="250"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        dim (int): Number of input channels.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="251"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="252"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="253"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def __init__(<span class="hljs-keyword">self</span>, dim, norm_layer<span class="hljs-operator">=</span>nn.LayerNorm):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="254"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">super</span>().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="255"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.dim <span class="hljs-operator">=</span> dim</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="256"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.reduction <span class="hljs-operator">=</span> nn.Linear(<span class="hljs-number">4</span> <span class="hljs-operator">*</span> dim, <span class="hljs-number">2</span> <span class="hljs-operator">*</span> dim, bias<span class="hljs-operator">=</span><span class="hljs-keyword">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="257"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.norm <span class="hljs-operator">=</span> norm_layer(<span class="hljs-number">4</span> <span class="hljs-operator">*</span> dim)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="258"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="259"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def forward(<span class="hljs-keyword">self</span>, x, H, W):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="260"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">" Forward function.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="261"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="262"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="263"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            x: Input feature, tensor size (B, H*W, C).</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="264"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            H, W: Spatial resolution of the input feature.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="265"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="266"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        B, L, C <span class="hljs-operator">=</span> x.shape</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="267"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        assert L <span class="hljs-operator">=</span><span class="hljs-operator">=</span> H <span class="hljs-operator">*</span> W, <span class="hljs-string">"input feature has wrong size"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="268"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="269"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> x.view(B, H, W, C)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="270"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="271"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # padding</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="272"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        pad_<span class="hljs-keyword">input</span> <span class="hljs-operator">=</span> (H % <span class="hljs-number">2</span> <span class="hljs-operator">=</span><span class="hljs-operator">=</span> <span class="hljs-number">1</span>) <span class="hljs-keyword">or</span> (W % <span class="hljs-number">2</span> <span class="hljs-operator">=</span><span class="hljs-operator">=</span> <span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="273"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> pad_<span class="hljs-keyword">input</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="274"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> F.pad(x, (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, W % <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, H % <span class="hljs-number">2</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="275"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="276"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x<span class="hljs-number">0</span> <span class="hljs-operator">=</span> x[:, <span class="hljs-number">0</span><span class="hljs-operator">::</span><span class="hljs-number">2</span>, <span class="hljs-number">0</span><span class="hljs-operator">::</span><span class="hljs-number">2</span>, :]  # B H<span class="hljs-operator">/</span><span class="hljs-number">2</span> W<span class="hljs-operator">/</span><span class="hljs-number">2</span> C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="277"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x<span class="hljs-number">1</span> <span class="hljs-operator">=</span> x[:, <span class="hljs-number">1</span><span class="hljs-operator">::</span><span class="hljs-number">2</span>, <span class="hljs-number">0</span><span class="hljs-operator">::</span><span class="hljs-number">2</span>, :]  # B H<span class="hljs-operator">/</span><span class="hljs-number">2</span> W<span class="hljs-operator">/</span><span class="hljs-number">2</span> C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="278"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x<span class="hljs-number">2</span> <span class="hljs-operator">=</span> x[:, <span class="hljs-number">0</span><span class="hljs-operator">::</span><span class="hljs-number">2</span>, <span class="hljs-number">1</span><span class="hljs-operator">::</span><span class="hljs-number">2</span>, :]  # B H<span class="hljs-operator">/</span><span class="hljs-number">2</span> W<span class="hljs-operator">/</span><span class="hljs-number">2</span> C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="279"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x<span class="hljs-number">3</span> <span class="hljs-operator">=</span> x[:, <span class="hljs-number">1</span><span class="hljs-operator">::</span><span class="hljs-number">2</span>, <span class="hljs-number">1</span><span class="hljs-operator">::</span><span class="hljs-number">2</span>, :]  # B H<span class="hljs-operator">/</span><span class="hljs-number">2</span> W<span class="hljs-operator">/</span><span class="hljs-number">2</span> C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="280"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> torch.cat([x<span class="hljs-number">0</span>, x<span class="hljs-number">1</span>, x<span class="hljs-number">2</span>, x<span class="hljs-number">3</span>], -<span class="hljs-number">1</span>)  # B H<span class="hljs-operator">/</span><span class="hljs-number">2</span> W<span class="hljs-operator">/</span><span class="hljs-number">2</span> <span class="hljs-number">4</span><span class="hljs-operator">*</span>C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="281"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> x.view(B, -<span class="hljs-number">1</span>, <span class="hljs-number">4</span> <span class="hljs-operator">*</span> C)  # B H<span class="hljs-operator">/</span><span class="hljs-number">2</span><span class="hljs-operator">*</span>W<span class="hljs-operator">/</span><span class="hljs-number">2</span> <span class="hljs-number">4</span><span class="hljs-operator">*</span>C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="282"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="283"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.norm(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="284"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.reduction(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="285"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="286"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="287"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="288"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="289"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> BasicLayer(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="290"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">" A basic Swin Transformer layer for one stage.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="291"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="292"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="293"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        dim (int): Number of feature channels</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="294"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        depth (int): Depths of this stage.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="295"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        num_heads (int): Number of attention head.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="296"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        window_size (int): Local window size. Default: 7.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="297"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="298"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="299"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="300"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        drop (float, optional): Dropout rate. Default: 0.0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="301"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        attn_drop (float, optional): Attention dropout rate. Default: 0.0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="302"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="303"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="304"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="305"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="306"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="307"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="308"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def __init__(<span class="hljs-keyword">self</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="309"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 dim,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="310"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 depth,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="311"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 num_heads,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="312"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 window_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span><span class="hljs-number">7</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="313"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 mlp_ratio<span class="hljs-operator">=</span><span class="hljs-number">4</span>.,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="314"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 qkv_bias<span class="hljs-operator">=</span><span class="hljs-keyword">True</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="315"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 qk_scale<span class="hljs-operator">=</span>None,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="316"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 drop<span class="hljs-operator">=</span><span class="hljs-number">0</span>.,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="317"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 attn_drop<span class="hljs-operator">=</span><span class="hljs-number">0</span>.,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="318"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 drop_path<span class="hljs-operator">=</span><span class="hljs-number">0</span>.,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="319"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 norm_layer<span class="hljs-operator">=</span>nn.LayerNorm,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="320"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 downsample<span class="hljs-operator">=</span>None,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="321"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 <span class="hljs-keyword">use</span>_checkpoint<span class="hljs-operator">=</span><span class="hljs-keyword">False</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="322"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">super</span>().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="323"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span> <span class="hljs-operator">=</span> window_<span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="324"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span> <span class="hljs-operator">=</span> window_<span class="hljs-keyword">size</span> <span class="hljs-operator">/</span><span class="hljs-operator">/</span> <span class="hljs-number">2</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="325"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.depth <span class="hljs-operator">=</span> depth</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="326"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.<span class="hljs-keyword">use</span>_checkpoint <span class="hljs-operator">=</span> <span class="hljs-keyword">use</span>_checkpoint</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="327"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="328"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # build blocks</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="329"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.blocks <span class="hljs-operator">=</span> nn.ModuleList([</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="330"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            SwinTransformerBlock(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="331"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                dim<span class="hljs-operator">=</span>dim,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="332"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                num_heads<span class="hljs-operator">=</span>num_heads,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="333"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                window_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span>window_<span class="hljs-keyword">size</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="334"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                shift_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span><span class="hljs-number">0</span> <span class="hljs-keyword">if</span> (i % <span class="hljs-number">2</span> <span class="hljs-operator">=</span><span class="hljs-operator">=</span> <span class="hljs-number">0</span>) <span class="hljs-keyword">else</span> window_<span class="hljs-keyword">size</span> <span class="hljs-operator">/</span><span class="hljs-operator">/</span> <span class="hljs-number">2</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="335"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                mlp_ratio<span class="hljs-operator">=</span>mlp_ratio,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="336"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                qkv_bias<span class="hljs-operator">=</span>qkv_bias,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="337"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                qk_scale<span class="hljs-operator">=</span>qk_scale,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="338"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                drop<span class="hljs-operator">=</span>drop,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="339"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                attn_drop<span class="hljs-operator">=</span>attn_drop,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="340"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                drop_path<span class="hljs-operator">=</span>drop_path[i] <span class="hljs-keyword">if</span> isinstance(drop_path, list) <span class="hljs-keyword">else</span> drop_path,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="341"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                norm_layer<span class="hljs-operator">=</span>norm_layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="342"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(depth)])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="343"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="344"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # patch merging layer</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="345"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> downsample <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> None:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="346"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">self</span>.downsample <span class="hljs-operator">=</span> downsample(dim<span class="hljs-operator">=</span>dim, norm_layer<span class="hljs-operator">=</span>norm_layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="347"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="348"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">self</span>.downsample <span class="hljs-operator">=</span> None</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="349"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="350"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def forward(<span class="hljs-keyword">self</span>, x, H, W):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="351"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">" Forward function.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="352"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="353"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="354"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            x: Input feature, tensor size (B, H*W, C).</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="355"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            H, W: Spatial resolution of the input feature.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="356"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="357"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="358"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # calculate attention mask <span class="hljs-keyword">for</span> SW-MSA</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="359"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        Hp <span class="hljs-operator">=</span> int(np.ceil(H <span class="hljs-operator">/</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>)) <span class="hljs-operator">*</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="360"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        Wp <span class="hljs-operator">=</span> int(np.ceil(W <span class="hljs-operator">/</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>)) <span class="hljs-operator">*</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="361"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        img_mask <span class="hljs-operator">=</span> torch.<span class="hljs-literal">zeros</span>((<span class="hljs-number">1</span>, Hp, Wp, <span class="hljs-number">1</span>), device<span class="hljs-operator">=</span>x.device)  # <span class="hljs-number">1</span> Hp Wp <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="362"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        h_slices <span class="hljs-operator">=</span> (slice(<span class="hljs-number">0</span>, -<span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="363"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    slice(-<span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>, -<span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="364"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    slice(-<span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span>, None))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="365"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        w_slices <span class="hljs-operator">=</span> (slice(<span class="hljs-number">0</span>, -<span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="366"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    slice(-<span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>, -<span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="367"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    slice(-<span class="hljs-keyword">self</span>.shift_<span class="hljs-keyword">size</span>, None))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="368"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        cnt <span class="hljs-operator">=</span> <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="369"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> h <span class="hljs-keyword">in</span> h_slices:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="370"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> w_slices:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="371"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                img_mask[:, h, w, :] <span class="hljs-operator">=</span> cnt</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="372"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                cnt <span class="hljs-operator">+</span><span class="hljs-operator">=</span> <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="373"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="374"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        mask_windows <span class="hljs-operator">=</span> window_partition(img_mask, <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>)  # nW, window_<span class="hljs-keyword">size</span>, window_<span class="hljs-keyword">size</span>, <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="375"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        mask_windows <span class="hljs-operator">=</span> mask_windows.view(-<span class="hljs-number">1</span>, <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">self</span>.window_<span class="hljs-keyword">size</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="376"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attn_mask <span class="hljs-operator">=</span> mask_windows.unsqueeze(<span class="hljs-number">1</span>)<span class="hljs-operator"> - </span>mask_windows.unsqueeze(<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="377"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attn_mask <span class="hljs-operator">=</span> attn_mask.masked_fill(attn_mask !<span class="hljs-operator">=</span> <span class="hljs-number">0</span>, float(-<span class="hljs-number">100.0</span>)).masked_fill(attn_mask <span class="hljs-operator">=</span><span class="hljs-operator">=</span> <span class="hljs-number">0</span>, float(<span class="hljs-number">0.0</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="378"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="379"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> blk <span class="hljs-keyword">in</span> <span class="hljs-keyword">self</span>.blocks:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="380"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            blk.H, blk.W <span class="hljs-operator">=</span> H, W</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="381"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.<span class="hljs-keyword">use</span>_checkpoint:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="382"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                x <span class="hljs-operator">=</span> checkpoint.checkpoint(blk, x, attn_mask)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="383"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="384"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                x <span class="hljs-operator">=</span> blk(x, attn_mask)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="385"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.downsample <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> None:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="386"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x_<span class="hljs-keyword">down</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.downsample(x, H, W)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="387"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Wh, Ww <span class="hljs-operator">=</span> (H <span class="hljs-operator">+</span> <span class="hljs-number">1</span>) <span class="hljs-operator">/</span><span class="hljs-operator">/</span> <span class="hljs-number">2</span>, (W <span class="hljs-operator">+</span> <span class="hljs-number">1</span>) <span class="hljs-operator">/</span><span class="hljs-operator">/</span> <span class="hljs-number">2</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="388"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> x, H, W, x_<span class="hljs-keyword">down</span>, Wh, Ww</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="389"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="390"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> x, H, W, x, H, W</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="391"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="392"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="393"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> PatchEmbed(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="394"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">" Image to Patch Embedding</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="395"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="396"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="397"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        patch_size (int): Patch token size. Default: 4.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="398"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        in_chans (int): Number of input image channels. Default: 3.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="399"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        embed_dim (int): Number of linear projection output channels. Default: 96.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="400"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        norm_layer (nn.Module, optional): Normalization layer. Default: None</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="401"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="402"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="403"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def __init__(<span class="hljs-keyword">self</span>, patch_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span><span class="hljs-number">4</span>, <span class="hljs-keyword">in</span>_chans<span class="hljs-operator">=</span><span class="hljs-number">3</span>, embed_dim<span class="hljs-operator">=</span><span class="hljs-number">96</span>, norm_layer<span class="hljs-operator">=</span>None):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="404"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">super</span>().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="405"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        patch_<span class="hljs-keyword">size</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">to</span>_<span class="hljs-number">2</span>tuple(patch_<span class="hljs-keyword">size</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="406"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.patch_<span class="hljs-keyword">size</span> <span class="hljs-operator">=</span> patch_<span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="407"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="408"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.<span class="hljs-keyword">in</span>_chans <span class="hljs-operator">=</span> <span class="hljs-keyword">in</span>_chans</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="409"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.embed_dim <span class="hljs-operator">=</span> embed_dim</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="410"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="411"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.proj <span class="hljs-operator">=</span> nn.Conv<span class="hljs-number">2</span>d(<span class="hljs-keyword">in</span>_chans, embed_dim, kernel_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span>patch_<span class="hljs-keyword">size</span>, stride<span class="hljs-operator">=</span>patch_<span class="hljs-keyword">size</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="412"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> norm_layer <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> None:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="413"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">self</span>.norm <span class="hljs-operator">=</span> norm_layer(embed_dim)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="414"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="415"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">self</span>.norm <span class="hljs-operator">=</span> None</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="416"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="417"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def forward(<span class="hljs-keyword">self</span>, x):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="418"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">""</span><span class="hljs-string">"Forward function."</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="419"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # padding</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="420"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        _, _, H, W <span class="hljs-operator">=</span> x.<span class="hljs-keyword">size</span>()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="421"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> W % <span class="hljs-keyword">self</span>.patch_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>] !<span class="hljs-operator">=</span> <span class="hljs-number">0</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="422"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> F.pad(x, (<span class="hljs-number">0</span>, <span class="hljs-keyword">self</span>.patch_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>]<span class="hljs-operator"> - </span>W % <span class="hljs-keyword">self</span>.patch_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>]))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="423"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> H % <span class="hljs-keyword">self</span>.patch_<span class="hljs-keyword">size</span>[<span class="hljs-number">0</span>] !<span class="hljs-operator">=</span> <span class="hljs-number">0</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="424"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> F.pad(x, (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-keyword">self</span>.patch_<span class="hljs-keyword">size</span>[<span class="hljs-number">0</span>]<span class="hljs-operator"> - </span>H % <span class="hljs-keyword">self</span>.patch_<span class="hljs-keyword">size</span>[<span class="hljs-number">0</span>]))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="425"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="426"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.proj(x)  # B C Wh Ww</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="427"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.norm <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> None:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="428"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Wh, Ww <span class="hljs-operator">=</span> x.<span class="hljs-keyword">size</span>(<span class="hljs-number">2</span>), x.<span class="hljs-keyword">size</span>(<span class="hljs-number">3</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="429"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> x.flatten(<span class="hljs-number">2</span>).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="430"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.norm(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="431"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).view(-<span class="hljs-number">1</span>, <span class="hljs-keyword">self</span>.embed_dim, Wh, Ww)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="432"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="433"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="434"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="435"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> SwinTransformer(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="436"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">" Swin Transformer backbone.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="437"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="438"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">          https://arxiv.org/pdf/2103.14030</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="439"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="440"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="441"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        pretrain_img_size (int): Input image size for training the pretrained model,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="442"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            used in absolute postion embedding. Default 224.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="443"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        patch_size (int | tuple(int)): Patch size. Default: 4.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="444"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        in_chans (int): Number of input image channels. Default: 3.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="445"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        embed_dim (int): Number of linear projection output channels. Default: 96.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="446"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        depths (tuple[int]): Depths of each Swin Transformer stage.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="447"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        num_heads (tuple[int]): Number of attention head of each stage.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="448"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        window_size (int): Window size. Default: 7.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="449"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="450"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="451"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="452"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        drop_rate (float): Dropout rate.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="453"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        attn_drop_rate (float): Attention dropout rate. Default: 0.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="454"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        drop_path_rate (float): Stochastic depth rate. Default: 0.2.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="455"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="456"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="457"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        patch_norm (bool): If True, add normalization after patch embedding. Default: True.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="458"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        out_indices (Sequence[int]): Output from which stages.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="459"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        frozen_stages (int): Stages to be frozen (stop grad and set eval mode).</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="460"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            -1 means not freezing any parameters.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="461"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="462"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="463"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="464"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def __init__(<span class="hljs-keyword">self</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="465"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 pretrain_img_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span><span class="hljs-number">224</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="466"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 patch_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span><span class="hljs-number">4</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="467"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 <span class="hljs-keyword">in</span>_chans<span class="hljs-operator">=</span><span class="hljs-number">3</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="468"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 embed_dim<span class="hljs-operator">=</span><span class="hljs-number">96</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="469"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 depths<span class="hljs-operator">=</span>[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="470"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 num_heads<span class="hljs-operator">=</span>[<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">12</span>, <span class="hljs-number">24</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="471"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 window_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span><span class="hljs-number">7</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="472"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 mlp_ratio<span class="hljs-operator">=</span><span class="hljs-number">4</span>.,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="473"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 qkv_bias<span class="hljs-operator">=</span><span class="hljs-keyword">True</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="474"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 qk_scale<span class="hljs-operator">=</span>None,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="475"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 drop_rate<span class="hljs-operator">=</span><span class="hljs-number">0</span>.,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="476"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 attn_drop_rate<span class="hljs-operator">=</span><span class="hljs-number">0</span>.,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="477"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 drop_path_rate<span class="hljs-operator">=</span><span class="hljs-number">0.2</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="478"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 norm_layer<span class="hljs-operator">=</span>nn.LayerNorm,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="479"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 ape<span class="hljs-operator">=</span><span class="hljs-keyword">False</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="480"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 patch_norm<span class="hljs-operator">=</span><span class="hljs-keyword">True</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="481"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 out_indices<span class="hljs-operator">=</span>(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="482"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 frozen_stages<span class="hljs-operator">=</span>-<span class="hljs-number">1</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="483"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                 <span class="hljs-keyword">use</span>_checkpoint<span class="hljs-operator">=</span><span class="hljs-keyword">False</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="484"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">super</span>().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="485"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="486"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.pretrain_img_<span class="hljs-keyword">size</span> <span class="hljs-operator">=</span> pretrain_img_<span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="487"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.num_layers <span class="hljs-operator">=</span> len(depths)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="488"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.embed_dim <span class="hljs-operator">=</span> embed_dim</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="489"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.ape <span class="hljs-operator">=</span> ape</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="490"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.patch_norm <span class="hljs-operator">=</span> patch_norm</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="491"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.out_indices <span class="hljs-operator">=</span> out_indices</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="492"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.frozen_stages <span class="hljs-operator">=</span> frozen_stages</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="493"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="494"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # split image <span class="hljs-keyword">into</span> non-overlapping patches</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="495"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.patch_embed <span class="hljs-operator">=</span> PatchEmbed(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="496"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            patch_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span>patch_<span class="hljs-keyword">size</span>, <span class="hljs-keyword">in</span>_chans<span class="hljs-operator">=</span><span class="hljs-keyword">in</span>_chans, embed_dim<span class="hljs-operator">=</span>embed_dim,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="497"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            norm_layer<span class="hljs-operator">=</span>norm_layer <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.patch_norm <span class="hljs-keyword">else</span> None)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="498"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="499"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # absolute position embedding</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="500"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.ape:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="501"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            pretrain_img_<span class="hljs-keyword">size</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">to</span>_<span class="hljs-number">2</span>tuple(pretrain_img_<span class="hljs-keyword">size</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="502"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            patch_<span class="hljs-keyword">size</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">to</span>_<span class="hljs-number">2</span>tuple(patch_<span class="hljs-keyword">size</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="503"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            patches_resolution <span class="hljs-operator">=</span> [pretrain_img_<span class="hljs-keyword">size</span>[<span class="hljs-number">0</span>] <span class="hljs-operator">/</span><span class="hljs-operator">/</span> patch_<span class="hljs-keyword">size</span>[<span class="hljs-number">0</span>], pretrain_img_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>] <span class="hljs-operator">/</span><span class="hljs-operator">/</span> patch_<span class="hljs-keyword">size</span>[<span class="hljs-number">1</span>]]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="504"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="505"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">self</span>.absolute_pos_embed <span class="hljs-operator">=</span> nn.Parameter(torch.<span class="hljs-literal">zeros</span>(<span class="hljs-number">1</span>, embed_dim, patches_resolution[<span class="hljs-number">0</span>], patches_resolution[<span class="hljs-number">1</span>]))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="506"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            trunc_normal_(<span class="hljs-keyword">self</span>.absolute_pos_embed, std<span class="hljs-operator">=</span>.<span class="hljs-number">02</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="507"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="508"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.pos_drop <span class="hljs-operator">=</span> nn.Dropout(p<span class="hljs-operator">=</span>drop_rate)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="509"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="510"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # stochastic depth</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="511"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        dpr <span class="hljs-operator">=</span> [x.item() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> torch.linspace(<span class="hljs-number">0</span>, drop_path_rate, <span class="hljs-keyword">sum</span>(depths))]  # stochastic depth decay rule</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="512"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="513"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # build layers</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="514"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.layers <span class="hljs-operator">=</span> nn.ModuleList()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="515"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> i_layer <span class="hljs-keyword">in</span> range(<span class="hljs-keyword">self</span>.num_layers):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="516"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            layer <span class="hljs-operator">=</span> BasicLayer(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="517"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                dim<span class="hljs-operator">=</span>int(embed_dim <span class="hljs-operator">*</span> <span class="hljs-number">2</span> <span class="hljs-operator">**</span> i_layer),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="518"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                depth<span class="hljs-operator">=</span>depths[i_layer],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="519"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                num_heads<span class="hljs-operator">=</span>num_heads[i_layer],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="520"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                window_<span class="hljs-keyword">size</span><span class="hljs-operator">=</span>window_<span class="hljs-keyword">size</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="521"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                mlp_ratio<span class="hljs-operator">=</span>mlp_ratio,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="522"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                qkv_bias<span class="hljs-operator">=</span>qkv_bias,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="523"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                qk_scale<span class="hljs-operator">=</span>qk_scale,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="524"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                drop<span class="hljs-operator">=</span>drop_rate,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="525"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                attn_drop<span class="hljs-operator">=</span>attn_drop_rate,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="526"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                drop_path<span class="hljs-operator">=</span>dpr[<span class="hljs-keyword">sum</span>(depths[:i_layer]):<span class="hljs-keyword">sum</span>(depths[:i_layer <span class="hljs-operator">+</span> <span class="hljs-number">1</span>])],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="527"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                norm_layer<span class="hljs-operator">=</span>norm_layer,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="528"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                downsample<span class="hljs-operator">=</span>PatchMerging <span class="hljs-keyword">if</span> (i_layer <span class="hljs-operator">&lt;</span> <span class="hljs-keyword">self</span>.num_layers<span class="hljs-operator"> - </span><span class="hljs-number">1</span>) <span class="hljs-keyword">else</span> None,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="529"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-keyword">use</span>_checkpoint<span class="hljs-operator">=</span><span class="hljs-keyword">use</span>_checkpoint)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="530"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">self</span>.layers.append(layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="531"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="532"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        num_features <span class="hljs-operator">=</span> [int(embed_dim <span class="hljs-operator">*</span> <span class="hljs-number">2</span> <span class="hljs-operator">**</span> i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-keyword">self</span>.num_layers)]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="533"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.num_features <span class="hljs-operator">=</span> num_features</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="534"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="535"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        # <span class="hljs-keyword">add</span> a norm layer <span class="hljs-keyword">for</span> each <span class="hljs-keyword">output</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="536"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> i_layer <span class="hljs-keyword">in</span> out_indices:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="537"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            layer <span class="hljs-operator">=</span> norm_layer(num_features[i_layer])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="538"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            layer_name <span class="hljs-operator">=</span> f<span class="hljs-string">'norm{i_layer}'</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="539"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">self</span>.<span class="hljs-keyword">add</span>_module(layer_name, layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="540"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">self</span>.width_list <span class="hljs-operator">=</span> [i.<span class="hljs-keyword">size</span>(<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">self</span>.forward(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">640</span>, <span class="hljs-number">640</span>))]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="541"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="542"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def forward(<span class="hljs-keyword">self</span>, x):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="543"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">""</span><span class="hljs-string">"Forward function."</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="544"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.patch_embed(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="545"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="546"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        Wh, Ww <span class="hljs-operator">=</span> x.<span class="hljs-keyword">size</span>(<span class="hljs-number">2</span>), x.<span class="hljs-keyword">size</span>(<span class="hljs-number">3</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="547"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.ape:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="548"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            # interpolate the position embedding <span class="hljs-keyword">to</span> the <span class="hljs-keyword">corresponding</span> <span class="hljs-keyword">size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="549"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            absolute_pos_embed <span class="hljs-operator">=</span> F.interpolate(<span class="hljs-keyword">self</span>.absolute_pos_embed, <span class="hljs-keyword">size</span><span class="hljs-operator">=</span>(Wh, Ww), <span class="hljs-keyword">mode</span><span class="hljs-operator">=</span><span class="hljs-string">'bicubic'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="550"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> (x <span class="hljs-operator">+</span> absolute_pos_embed).flatten(<span class="hljs-number">2</span>).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)  # B Wh<span class="hljs-operator">*</span>Ww C</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="551"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="552"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x <span class="hljs-operator">=</span> x.flatten(<span class="hljs-number">2</span>).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="553"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.pos_drop(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="554"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="555"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outs <span class="hljs-operator">=</span> []</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="556"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-keyword">self</span>.num_layers):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="557"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            layer <span class="hljs-operator">=</span> <span class="hljs-keyword">self</span>.layers[i]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="558"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            x_out, H, W, x, Wh, Ww <span class="hljs-operator">=</span> layer(x, Wh, Ww)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="559"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="560"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">self</span>.out_indices:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="561"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                norm_layer <span class="hljs-operator">=</span> getattr(<span class="hljs-keyword">self</span>, f<span class="hljs-string">'norm{i}'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="562"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                x_out <span class="hljs-operator">=</span> norm_layer(x_out)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="563"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="564"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                out <span class="hljs-operator">=</span> x_out.view(-<span class="hljs-number">1</span>, H, W, <span class="hljs-keyword">self</span>.num_features[i]).permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="565"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                outs.append(out)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="566"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="567"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> outs</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
<h2 id="%E5%9B%9B%E3%80%81%E6%89%8B%E6%8A%8A%E6%89%8B%E5%8F%AB%E4%BD%A0%E5%A4%A9EfficienViT%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><a name="t9"></a>&nbsp;四、手把手教你添加Swin Transformer网络结构</h2> 
<p>这个主干的网络结构添加起来算是所有的改进机制里最麻烦的了，因为有一些网略结构可以用yaml文件搭建出来，有一些网络结构其中的一些细节根本没有办法用yaml文件去搭建，用yaml文件去搭建会损失一些细节部分(而且一个网络结构设计很多细节的结构修改方式都不一样，一个一个去修改大家难免会出错)，所以这里让网络直接返回整个网络，然后修改部分 yolo代码以后就都以这种形式添加了，以后我提出的网络模型基本上都会通过这种方式修改，我也会进行一些模型细节改进。创新出新的网络结构大家直接拿来用就可以的。<span style="color:#fe2c24;"><strong>下面开始添加教程-&gt;</strong></span></p> 
<p><span style="color:#1a439c;"><strong>(同时每一个后面都有代码，大家拿来复制粘贴替换即可，但是要看好了不要复制粘贴替换多了)</strong></span></p> 
<p></p> 
<hr> 
<h3 id="%E4%BF%AE%E6%94%B9%E4%B8%80"><a name="t10"></a>修改一</h3> 
<p>我们复制网络结构代码到“ultralytics/nn/modules”目录下创建一个py文件复制粘贴进去 ，我这里起的名字是SwinTransformer。</p> 
<p class="img-center"><img alt="" height="358" src="https://img-blog.csdnimg.cn/direct/2e683c23baba49769a9e94e7b7413bbf.png" width="474"></p> 
<p></p> 
<hr> 
<h3 id="%E4%BF%AE%E6%94%B9%E4%BA%8C"><a name="t11"></a>修改二</h3> 
<p>找到如下的文件"ultralytics/nn/tasks.py" 在开始的部分导入我们的模型如下图。</p> 
<p class="img-center"><img alt="" height="117" src="https://img-blog.csdnimg.cn/direct/aa5f92d0fc784947a542e8bd80ed2651.png" width="1200"></p> 
<pre data-index="1" class="set-code-show" name="code"><code class="hljs language-typescript"><span class="hljs-keyword">from</span> .<span class="hljs-property">modules</span>.<span class="hljs-property">SwinTransformer</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">SwinTransformer</span>
</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
<p></p> 
<hr> 
<h3 id="%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0"><a name="t12"></a>修改三&nbsp;</h3> 
<p><span style="color:#fe2c24;"><strong>添加如下两行代码！！！</strong></span></p> 
<p class="img-center"><img alt="" height="261" src="https://img-blog.csdnimg.cn/direct/1655de23b1834dfca4f304336f0f2c19.png" width="867"></p> 
<p></p> 
<hr> 
<h3 id="%E4%BF%AE%E6%94%B9%E5%9B%9B"><a name="t13"></a>修改四</h3> 
<p>找到七百多行大概把具体看图片，按照图片来修改就行，添加红框内的部分，注意没有()只是函数名。</p> 
<p><img alt="" height="523" src="https://img-blog.csdnimg.cn/direct/23edbb006f6248a49c6dab4e8f7f65ba.png" width="1146"></p> 
<pre data-index="2" class="set-code-show" name="code"><code class="hljs language-cobol"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        elif m <span class="hljs-keyword">in</span> {SwinTransformer}:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            m <span class="hljs-operator">=</span> m()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            c<span class="hljs-number">2</span> <span class="hljs-operator">=</span> m.width_list  # 返回通道列表</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            backbone <span class="hljs-operator">=</span> <span class="hljs-keyword">True</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
<p></p> 
<hr> 
<h3 id="%E4%BF%AE%E6%94%B9%E4%BA%94%C2%A0"><a name="t14"></a>修改五&nbsp;</h3> 
<p>下面的两个红框内都是需要改动的。&nbsp;</p> 
<p><img alt="" height="223" src="https://img-blog.csdnimg.cn/direct/6437a57f982c4388a83b7be05cf64448.png" width="968"></p> 
<pre data-index="3" class="set-code-show" name="code"><code class="hljs language-cobol"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> isinstance(c<span class="hljs-number">2</span>, list):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            m_ <span class="hljs-operator">=</span> m</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            m_.backbone <span class="hljs-operator">=</span> <span class="hljs-keyword">True</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            m_ <span class="hljs-operator">=</span> nn.<span class="hljs-keyword">Sequential</span>(<span class="hljs-operator">*</span>(m(<span class="hljs-operator">*</span>args) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(n))) <span class="hljs-keyword">if</span> n <span class="hljs-operator">&gt;</span> <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> m(<span class="hljs-operator">*</span>args)  # module</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            t <span class="hljs-operator">=</span> str(m)[<span class="hljs-number">8</span>:-<span class="hljs-number">2</span>].<span class="hljs-keyword">replace</span>(<span class="hljs-string">'__main__.'</span>, <span class="hljs-string">''</span>)  # module <span class="hljs-keyword">type</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        m.np <span class="hljs-operator">=</span> <span class="hljs-keyword">sum</span>(x.numel() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> m_.parameters())  # <span class="hljs-keyword">number</span> params</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        m_.i, m_.f, m_.<span class="hljs-keyword">type</span> <span class="hljs-operator">=</span> i <span class="hljs-operator">+</span> <span class="hljs-number">4</span> <span class="hljs-keyword">if</span> backbone <span class="hljs-keyword">else</span> i, f, t  # attach <span class="hljs-keyword">index</span>, <span class="hljs-string">'from'</span> <span class="hljs-keyword">index</span>, <span class="hljs-keyword">type</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
<p></p> 
<hr> 
<h3 id="%E4%BF%AE%E6%94%B9%E5%85%AD%C2%A0"><a name="t15"></a>修改六&nbsp;</h3> 
<p>如下的也需要修改，全部按照我的来。</p> 
<p><img alt="" height="248" src="https://img-blog.csdnimg.cn/direct/7b6a03061e7e4846b51bc282e88bead8.png" width="1142"></p> 
<p>代码如下把原先的代码替换了即可。&nbsp;</p> 
<pre data-index="4" class="set-code-show" name="code"><code class="hljs language-cobol"><ol class="hljs-ln" style="width:1059px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        save.<span class="hljs-keyword">extend</span>(x % (i <span class="hljs-operator">+</span> <span class="hljs-number">4</span> <span class="hljs-keyword">if</span> backbone <span class="hljs-keyword">else</span> i) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> ([f] <span class="hljs-keyword">if</span> isinstance(f, int) <span class="hljs-keyword">else</span> f) <span class="hljs-keyword">if</span> x !<span class="hljs-operator">=</span> -<span class="hljs-number">1</span>)  # append <span class="hljs-keyword">to</span> savelist</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        layers.append(m_)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> i <span class="hljs-operator">=</span><span class="hljs-operator">=</span> <span class="hljs-number">0</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">ch</span> <span class="hljs-operator">=</span> []</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> isinstance(c<span class="hljs-number">2</span>, list):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">ch</span>.<span class="hljs-keyword">extend</span>(c<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> len(c<span class="hljs-number">2</span>) !<span class="hljs-operator">=</span> <span class="hljs-number">5</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-keyword">ch</span>.insert(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">ch</span>.append(c<span class="hljs-number">2</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
<p></p> 
<hr> 
<h3 id="%E4%BF%AE%E6%94%B9%E4%B8%83"><a name="t16"></a>修改七</h3> 
<p>修改七和前面的都不太一样，需要修改前向传播中的一个部分，&nbsp;已经离开了parse_model方法了。</p> 
<p>可以在图片中开代码行数，没有离开task.py文件都是同一个文件。 同时这个部分有好几个前向传播都很相似，大家不要看错了，<strong>是70多行左右的！！！，同时我后面提供了代码，大家直接复制粘贴即可，有时间我针对这里会出一个视频。</strong></p> 
<p class="img-center"><img alt="" height="751" src="https://img-blog.csdnimg.cn/direct/c2ad3781e93f4f01ac1cfab9b90ed1bb.png" width="1200"></p> 
<p><strong>代码如下-&gt;</strong></p> 
<pre data-index="5" class="set-code-show" name="code"><code class="hljs language-cobol"><ol class="hljs-ln" style="width:967px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    def _predict_once(<span class="hljs-keyword">self</span>, x, profile<span class="hljs-operator">=</span><span class="hljs-keyword">False</span>, visualize<span class="hljs-operator">=</span><span class="hljs-keyword">False</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">""</span><span class="hljs-string"><span class="hljs-string">"</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        Perform a forward pass through the network.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        Args:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            x (torch.Tensor): The input tensor to the model.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            profile (bool):  Print the computation time of each layer if True, defaults to False.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            visualize (bool): Save the feature maps of the model if True, defaults to False.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        Returns:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            (torch.Tensor): The last output of the model.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        "</span><span class="hljs-string">""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        y, dt <span class="hljs-operator">=</span> [], []  # outputs</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-keyword">self</span>.model:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> m.f !<span class="hljs-operator">=</span> -<span class="hljs-number">1</span>:  # <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">from</span> previous layer</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                x <span class="hljs-operator">=</span> y[m.f] <span class="hljs-keyword">if</span> isinstance(m.f, int) <span class="hljs-keyword">else</span> [x <span class="hljs-keyword">if</span> j <span class="hljs-operator">=</span><span class="hljs-operator">=</span> -<span class="hljs-number">1</span> <span class="hljs-keyword">else</span> y[j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> m.f]  # <span class="hljs-keyword">from</span> earlier layers</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> profile:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-keyword">self</span>._profile_one_layer(m, x, dt)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> hasattr(m, <span class="hljs-string">'backbone'</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                x <span class="hljs-operator">=</span> m(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-keyword">if</span> len(x) !<span class="hljs-operator">=</span> <span class="hljs-number">5</span>: # <span class="hljs-number">0</span><span class="hljs-operator"> - </span><span class="hljs-number">5</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    x.insert(<span class="hljs-number">0</span>, None)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-keyword">for</span> <span class="hljs-keyword">index</span>, i <span class="hljs-keyword">in</span> enumerate(x):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    <span class="hljs-keyword">if</span> <span class="hljs-keyword">index</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">self</span>.save:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                        y.append(i)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                        y.append(None)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                x <span class="hljs-operator">=</span> x[-<span class="hljs-number">1</span>] # 最后一个输出传给下一层</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                x <span class="hljs-operator">=</span> m(x)  # <span class="hljs-keyword">run</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                y.append(x <span class="hljs-keyword">if</span> m.i <span class="hljs-keyword">in</span> <span class="hljs-keyword">self</span>.save <span class="hljs-keyword">else</span> None)  # save <span class="hljs-keyword">output</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> visualize:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                feature_visualization(x, m.<span class="hljs-keyword">type</span>, m.i, save_dir<span class="hljs-operator">=</span>visualize)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
<p>到这里就完成了修改部分，但是这里面细节很多，大家千万要注意不要替换多余的代码，导致报错，也不要拉下任何一部，都会导致运行失败，而且报错很难排查！！！很难排查！！！&nbsp;</p> 
<p></p> 
<hr> 
<h3 id="%E4%BF%AE%E6%94%B9%E5%85%AB"><a name="t17"></a>修改八</h3> 
<p>这个Swin Transformer和其他的不太一样会导致计算的GFLOPs计算异常，所以需要额外修改一处，&nbsp;我们找到如下文件'ultralytics/utils/torch_utils.py'按照如下的图片进行修改。</p> 
<p class="img-center"><img alt="" height="288" src="https://img-blog.csdnimg.cn/direct/24068f6039b94ceeb91e98642c00e594.png" width="1095"></p> 
<p></p> 
<h2 id="%E4%BA%94%E3%80%81EfficientViT2023yaml%E6%96%87%E4%BB%B6"><a name="t18"></a>五、Swin Transformer的yaml文件</h2> 
<p><strong>复制如下yaml文件进行运行！！！&nbsp;</strong></p> 
<pre data-index="6" class="set-code-show" name="code"><code class="hljs language-cobol"><ol class="hljs-ln" style="width:967px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"># Ultralytics YOLO 🚀, AGPL-<span class="hljs-number">3.0</span> license</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"># YOLOv<span class="hljs-number">8</span> <span class="hljs-keyword">object</span> detection model <span class="hljs-keyword">with</span> P<span class="hljs-number">3</span>-P<span class="hljs-number">5</span> outputs. <span class="hljs-keyword">For</span> <span class="hljs-keyword">Usage</span> examples see https:<span class="hljs-operator">/</span><span class="hljs-operator">/</span>docs.ultralytics.com<span class="hljs-operator">/</span>tasks<span class="hljs-operator">/</span>detect</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"># Parameters</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">nc: <span class="hljs-number">80</span>  # <span class="hljs-keyword">number</span> <span class="hljs-keyword">of</span> classes</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">scales: # model compound scaling constants, i.e. <span class="hljs-string">'model=yolov8n.yaml'</span> will <span class="hljs-keyword">call</span> yolov<span class="hljs-number">8</span>.yaml <span class="hljs-keyword">with</span> scale <span class="hljs-string">'n'</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  # [depth, width, max_channels]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  n: [<span class="hljs-number">0.33</span>, <span class="hljs-number">0.25</span>, <span class="hljs-number">1024</span>]  # YOLOv<span class="hljs-number">8</span>n summary: <span class="hljs-number">225</span> layers,  <span class="hljs-number">3157200</span> parameters,  <span class="hljs-number">3157184</span> gradients,   <span class="hljs-number">8.9</span> GFLOPs</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  s: [<span class="hljs-number">0.33</span>, <span class="hljs-number">0.50</span>, <span class="hljs-number">1024</span>]  # YOLOv<span class="hljs-number">8</span>s summary: <span class="hljs-number">225</span> layers, <span class="hljs-number">11166560</span> parameters, <span class="hljs-number">11166544</span> gradients,  <span class="hljs-number">28.8</span> GFLOPs</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  m: [<span class="hljs-number">0.67</span>, <span class="hljs-number">0.75</span>, <span class="hljs-number">768</span>]   # YOLOv<span class="hljs-number">8</span>m summary: <span class="hljs-number">295</span> layers, <span class="hljs-number">25902640</span> parameters, <span class="hljs-number">25902624</span> gradients,  <span class="hljs-number">79.3</span> GFLOPs</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  l: [<span class="hljs-number">1.00</span>, <span class="hljs-number">1.00</span>, <span class="hljs-number">512</span>]   # YOLOv<span class="hljs-number">8</span>l summary: <span class="hljs-number">365</span> layers, <span class="hljs-number">43691520</span> parameters, <span class="hljs-number">43691504</span> gradients, <span class="hljs-number">165.7</span> GFLOPs</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  x: [<span class="hljs-number">1.00</span>, <span class="hljs-number">1.25</span>, <span class="hljs-number">512</span>]   # YOLOv<span class="hljs-number">8</span>x summary: <span class="hljs-number">365</span> layers, <span class="hljs-number">68229648</span> parameters, <span class="hljs-number">68229632</span> gradients, <span class="hljs-number">258.5</span> GFLOPs</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"># YOLOv<span class="hljs-number">8.0</span>n backbone</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">backbone:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  # [<span class="hljs-keyword">from</span>, repeats, module, args]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, SwinTransformer, []]  # <span class="hljs-number">4</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, SPPF, [<span class="hljs-number">1024</span>, <span class="hljs-number">5</span>]]  # <span class="hljs-number">5</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"># YOLOv<span class="hljs-number">8.0</span>n head</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">head:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, nn.Upsample, [None, <span class="hljs-number">2</span>, <span class="hljs-string">'nearest'</span>]] # <span class="hljs-number">6</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[[-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>], <span class="hljs-number">1</span>, Concat, [<span class="hljs-number">1</span>]]  # <span class="hljs-number">7</span> cat backbone P<span class="hljs-number">4</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, C<span class="hljs-number">2</span>f, [<span class="hljs-number">512</span>]]  # <span class="hljs-number">8</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, nn.Upsample, [None, <span class="hljs-number">2</span>, <span class="hljs-string">'nearest'</span>]] # <span class="hljs-number">9</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[[-<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], <span class="hljs-number">1</span>, Concat, [<span class="hljs-number">1</span>]]  # <span class="hljs-number">10</span> cat backbone P<span class="hljs-number">3</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, C<span class="hljs-number">2</span>f, [<span class="hljs-number">256</span>]]  # <span class="hljs-number">11</span> (P<span class="hljs-number">3</span><span class="hljs-operator">/</span><span class="hljs-number">8</span>-small)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, Conv, [<span class="hljs-number">256</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]] # <span class="hljs-number">12</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[[-<span class="hljs-number">1</span>, <span class="hljs-number">8</span>], <span class="hljs-number">1</span>, Concat, [<span class="hljs-number">1</span>]]  # <span class="hljs-number">13</span> cat head P<span class="hljs-number">4</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, C<span class="hljs-number">2</span>f, [<span class="hljs-number">512</span>]]  # <span class="hljs-number">14</span> (P<span class="hljs-number">4</span><span class="hljs-operator">/</span><span class="hljs-number">16</span>-medium)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, Conv, [<span class="hljs-number">512</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]] # <span class="hljs-number">15</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[[-<span class="hljs-number">1</span>, <span class="hljs-number">5</span>], <span class="hljs-number">1</span>, Concat, [<span class="hljs-number">1</span>]]  # <span class="hljs-number">16</span> cat head P<span class="hljs-number">5</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, C<span class="hljs-number">2</span>f, [<span class="hljs-number">1024</span>]]  # <span class="hljs-number">17</span> (P<span class="hljs-number">5</span><span class="hljs-operator">/</span><span class="hljs-number">32</span>-large)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> <span class="hljs-operator"> - </span>[[<span class="hljs-number">11</span>, <span class="hljs-number">14</span>, <span class="hljs-number">17</span>], <span class="hljs-number">1</span>, Detect, [nc]]  # Detect(P<span class="hljs-number">3</span>, P<span class="hljs-number">4</span>, P<span class="hljs-number">5</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
<p></p> 
<hr> 
<h2 id="%E5%85%AD%E3%80%81%E6%88%90%E5%8A%9F%E8%BF%90%E8%A1%8C%E8%AE%B0%E5%BD%95%C2%A0"><a name="t19"></a>六、成功运行记录&nbsp;</h2> 
<p>下面是成功运行的截图，已经完成了有1个epochs的训练，图片太大截不全第2个epochs了。&nbsp;</p> 
<p class="img-center"><img alt="" height="862" src="https://img-blog.csdnimg.cn/direct/257fc2c7e27e4091abee2ffb9e9fee0d.png" width="1180"></p> 
<p></p> 
<hr> 
<h2 id="%E5%85%AD%E3%80%81%E6%9C%AC%E6%96%87%E6%80%BB%E7%BB%93"><a name="t20"></a>七、本文总结</h2> 
<p>到此本文的正式分享内容就结束了，在这里给大家推荐我的YOLOv8改进有效涨点专栏，本专栏目前为新开的平均质量分98分，后期我会根据各种最新的前沿顶会进行论文复现，也会对一些老的改进机制进行补充，<span style="color:#fe2c24;"><strong>目前本专栏免费阅读(暂时，大家尽早关注不迷路~)</strong></span>，如果大家觉得本文帮助到你了，订阅本专栏，关注后续更多的更新~</p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24;">专栏回顾：</span><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><a href="https://blog.csdn.net/java1314777/category_12483754.html" title="YOLOv8改进系列专栏——本专栏持续复习各种顶会内容——科研必备">YOLOv8改进系列专栏——本专栏持续复习各种顶会内容——科研必备</a></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p> 
</blockquote> 
<p><img alt="" height="396" src="https://img-blog.csdnimg.cn/direct/bd80c2385d0548e9a87edc73f9261794.gif" width="1200"></p> 
<p></p> 
<p></p>
                </div><div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://snu77.blog.csdn.net/article/details/134816259&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>
        </div>
            </div> 
            
              </main>     
       </body>
       </html>
    
            